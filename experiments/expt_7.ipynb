{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Detection with SIFT and ORB on gray image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from expt_utils import *\n",
    "from matplotlib.patches import Rectangle\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_to_prewitt_edges(img, kernel_size=(3, 3)):\n",
    "    img_blur = cv.blur(img, kernel_size)\n",
    "    kernelx = np.array([[1, 1, 1], [0, 0, 0], [-1, -1, -1]])\n",
    "    kernely = np.array([[-1, 0, 1], [-1, 0, 1], [-1, 0, 1]])\n",
    "    img_prewittx = cv.filter2D(img_blur, cv.CV_64F, kernelx)\n",
    "    img_prewitty = cv.filter2D(img_blur, cv.CV_64F, kernely)\n",
    "    img_prewitt = cv.magnitude(img_prewittx, img_prewitty)\n",
    "    return img_prewitt\n",
    "\n",
    "\n",
    "def img_to_rebert_cross_edges(img, kernel_size=(3, 3)):\n",
    "    img_blur = cv.blur(img, kernel_size)\n",
    "    roberts_x = np.array([[1, 0], [0, -1]], dtype=np.float32)\n",
    "    roberts_y = np.array([[0, 1], [-1, 0]], dtype=np.float32)\n",
    "    roberts_x_edge = cv.filter2D(img_blur, cv.CV_64F, roberts_x)\n",
    "    roberts_y_edge = cv.filter2D(img_blur, cv.CV_64F, roberts_y)\n",
    "    img_roberts = cv.magnitude(roberts_x_edge, roberts_y_edge)\n",
    "    return img_roberts\n",
    "\n",
    "\n",
    "def img_to_frei_chen_edges(img, kernel_size=(3, 3)):\n",
    "    img_blur = cv.blur(img, kernel_size)\n",
    "    frei_chen_x = np.array(\n",
    "        [[1, np.sqrt(2), 1], [0, 0, 0], [-1, -np.sqrt(2), -1]], dtype=np.float32)\n",
    "    frei_chen_y = np.array(\n",
    "        [[-1, 0, 1], [-np.sqrt(2), 0, np.sqrt(2)], [-1, 0, 1]], dtype=np.float32)\n",
    "    frei_chen_x_edge = cv.filter2D(img_blur, cv.CV_64F, frei_chen_x)\n",
    "    frei_chen_y_edge = cv.filter2D(img_blur, cv.CV_64F, frei_chen_y)\n",
    "    img_frei_chen = cv.magnitude(frei_chen_x_edge, frei_chen_y_edge)\n",
    "    return img_frei_chen\n",
    "\n",
    "\n",
    "def img_to_cragis_edges(img, kernel_size=(3, 3)):\n",
    "    image_blur = cv.GaussianBlur(img, kernel_size, 0)\n",
    "    craigs_x = cv.Sobel(image_blur, cv.CV_64F, 1, 0, ksize=3)\n",
    "    craigs_y = cv.Sobel(image_blur, cv.CV_64F, 0, 1, ksize=3)\n",
    "    img_craigs = cv.magnitude(craigs_x, craigs_y)\n",
    "    return img_craigs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread(f\"{DS_DIR}/train/images/00029_1640.jpg\")\n",
    "img_gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "gnd_trth_gray = cv.imread(f\"{IMG_DIR}/ground_truth/00029_1640.jpg\", 0)\n",
    "\n",
    "img_canny = img_to_canny_edges(img_gray)\n",
    "img_mexican_hat = img_to_mexican_hat(img_gray)\n",
    "img_hanny = img_to_hanny(img_gray)\n",
    "img_prewitt = img_to_prewitt_edges(img_gray)\n",
    "img_roberts = img_to_rebert_cross_edges(img_gray)\n",
    "img_frei_chen = img_to_frei_chen_edges(img_gray)\n",
    "img_craigs = img_to_cragis_edges(img_gray)\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "plt.subplot(3,3,1)\n",
    "plt.imshow(img_canny,cmap='gray')\n",
    "plt.title('Canny')\n",
    "\n",
    "plt.subplot(3,3,2)\n",
    "plt.imshow(img_mexican_hat,cmap='gray')\n",
    "plt.title('Mexican Hat')\n",
    "\n",
    "plt.subplot(3,3,3)\n",
    "plt.imshow(img_hanny,cmap='gray')\n",
    "plt.title('Hanny')\n",
    "\n",
    "plt.subplot(3,3,4)\n",
    "plt.imshow(img_prewitt,cmap='gray')\n",
    "plt.title('prewitt')\n",
    "\n",
    "plt.subplot(3,3,5)\n",
    "plt.imshow(img_roberts,cmap='gray')\n",
    "plt.title('roberts')\n",
    "\n",
    "plt.subplot(3,3,6)\n",
    "plt.imshow(img_frei_chen,cmap='gray')\n",
    "plt.title('frei_chen')\n",
    "\n",
    "plt.subplot(3,3,7)\n",
    "plt.imshow(img_craigs,cmap='gray')\n",
    "plt.title('craigs')\n",
    "\n",
    "plt.subplot(3,3,8)\n",
    "plt.imshow(img_gray,cmap='gray')\n",
    "plt.title('img_gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluate kernel size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_sizes = [num for num in range(1, 32) if num % 2 != 0]\n",
    "results_df = pd.DataFrame(columns=['Kernel Size', 'Canny', 'Mexican Hat', 'Hanny', 'Prewitt', 'Roberts', 'Frei-Chen', 'Craigs'])\n",
    "\n",
    "# img_blur = cv.blur(img_gray, (3,3))\n",
    "# for kernel_size in kernel_sizes:\n",
    "    \n",
    "#     img_canny_kernel = img_to_canny_edges(img_gray,(kernel_size,kernel_size))\n",
    "#     corrcof_canny = np.corrcoef(img_canny_kernel.flatten(), gnd_trth_gray.flatten())[0,1]\n",
    "\n",
    "#     img_mexican_hat_kernel = img_to_mexican_hat(img_gray,(kernel_size))\n",
    "#     corrcof_mexican_hat = np.corrcoef(img_mexican_hat_kernel.flatten(), gnd_trth_gray.flatten())[0,1]\n",
    "\n",
    "#     img_hanny_kernel = img_to_hanny(img_gray,(kernel_size,kernel_size))\n",
    "#     corrcof_hanny = np.corrcoef(img_hanny_kernel.flatten(), gnd_trth_gray.flatten())[0,1]\n",
    "    \n",
    "#     img_prewitt_kernel = img_to_prewitt_edges(img_gray,(kernel_size,kernel_size))\n",
    "#     corrcof_prewitt = np.corrcoef(img_prewitt_kernel.flatten(), gnd_trth_gray.flatten())[0,1]\n",
    "\n",
    "#     img_roberts_kernel = img_to_rebert_cross_edges(img_gray,(kernel_size,kernel_size))\n",
    "#     corrcof_roberts = np.corrcoef(img_roberts_kernel.flatten(), gnd_trth_gray.flatten())[0,1]\n",
    "\n",
    "#     img_frei_chen_kernel = img_to_frei_chen_edges(img_gray,(kernel_size,kernel_size))\n",
    "#     corrcof_frei_chen = np.corrcoef(img_frei_chen_kernel.flatten(), gnd_trth_gray.flatten())[0,1]\n",
    "\n",
    "#     img_craigs_kernel = img_to_cragis_edges(img_gray,(kernel_size,kernel_size))\n",
    "#     corrcof_craigs = np.corrcoef(img_craigs_kernel.flatten(), gnd_trth_gray.flatten())[0,1]\n",
    "    \n",
    "#     results_df.loc[len(results_df)] = [kernel_size, corrcof_canny, corrcof_mexican_hat, corrcof_hanny, corrcof_prewitt, corrcof_roberts, corrcof_frei_chen, corrcof_craigs]\n",
    "\n",
    "# results_df\n",
    "    \n",
    "    # plt.figure(figsize=(10,8))\n",
    "    # plt.imshow(detected_edges,cmap='gray')\n",
    "    # plt.title(f\"figure with size : {kernel_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# rescale the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def mysize(image):\n",
    "#     resizing_percentages = [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 1.1, 1.2]\n",
    "\n",
    "#     for percentage in resizing_percentages:\n",
    "#         new_width = int(image.shape[1] * percentage)\n",
    "#         new_height = int(image.shape[0] * percentage)\n",
    "\n",
    "#         resized_img = cv.resize(image, (new_width, new_height))\n",
    "#         resized_img_ground_truth = cv.resize(img_ground_truth_gray, (new_width, new_height))\n",
    "#         corrcof = np.corrcoef(resized_img.flatten(), resized_img_ground_truth.flatten())[0,1]\n",
    "#         print(percentage, corrcof)\n",
    "\n",
    "# mysize(img_mexican_hat)\n",
    "\n",
    "# print(np.unique(img_mexican_hat))\n",
    "# img_gray = cv.resize(img_gray, (int(img_gray.shape[1] * 0.4), int(img_gray.shape[0] * 0.4)))\n",
    "# img_mexican_hat = cv.resize(img_mexican_hat, (int(img_mexican_hat.shape[1] * 0.4), int(img_mexican_hat.shape[0] * 0.4)))\n",
    "# img_ground_truth_gray = cv.resize(img_ground_truth_gray, (int(img_ground_truth_gray.shape[1] * 0.4), int(img_ground_truth_gray.shape[0] * 0.4)))\n",
    "# plt.imshow(img_mexican_hat,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_mexican_hat = cv.normalize(img_mexican_hat, None, alpha=0, beta=255, norm_type=cv.NORM_MINMAX, dtype=cv.CV_8U)\n",
    "# sns.histplot(x=np.unique(gnd_trth_gray),bins=100)\n",
    "# _, binary_thresholded_image = cv.threshold(img_mexican_hat, 80, 255, cv.THRESH_BINARY)\n",
    "# # plt.imshow(binary_thresholded_image,cmap='gray')\n",
    "# print(np.unique(img_mexican_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature detection\n",
    "sift = cv.SIFT_create()\n",
    "\n",
    "keypoints_gray, descriptors_gray = sift.detectAndCompute(gnd_trth_gray, None)\n",
    "keypoints_edge, descriptors_edge = sift.detectAndCompute(img_mexican_hat, None)\n",
    "\n",
    "# object matching\n",
    "bf = cv.BFMatcher()\n",
    "\n",
    "matches = bf.knnMatch(descriptors_gray, descriptors_edge, k=2)\n",
    "\n",
    "good_matches = []\n",
    "total_correct = 0\n",
    "for m, n in matches:\n",
    "    if m.distance < 0.9 * n.distance: # if m distance (indicate to descripter to the grd_img) is less than 0.5 * n distance (indicate to descripter of the estimate_img) then it may belong to the object else it belong to the background\n",
    "        good_matches.append(m)\n",
    "        total_correct += 1\n",
    "\n",
    "img_matches = cv.drawMatches(gnd_trth_gray, keypoints_gray, img_mexican_hat, keypoints_edge, good_matches, None, flags=cv.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "\n",
    "ground_truth_keypoints = total_correct\n",
    "predicted_keypoints = len(keypoints_edge)\n",
    "\n",
    "ground_truth_labels = np.zeros(len(matches))\n",
    "predicted_labels = np.zeros(len(matches))\n",
    "for i, match in enumerate(matches):\n",
    "    if i in [m.queryIdx for m in good_matches]:  # check if the index is in good_matches\n",
    "        predicted_labels[i] = 1\n",
    "    if i < len(good_matches):\n",
    "        ground_truth_labels[i] = 1\n",
    "\n",
    "conf_matrix = confusion_matrix(ground_truth_labels, predicted_labels)\n",
    "\n",
    "print(f\"accuracy: {ground_truth_keypoints / predicted_keypoints :.2%}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"All Truth Keypoints\", len(keypoints_gray))\n",
    "print(\"All Estimated Keypoints\", len(keypoints_edge))\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.imshow(img_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature detection\n",
    "\n",
    "orb = cv.ORB_create()\n",
    "\n",
    "keypoints_gray, descriptors_gray = orb.detectAndCompute(gnd_trth_gray, None)\n",
    "keypoints_edge, descriptors_edge = orb.detectAndCompute(img_mexican_hat, None)\n",
    "\n",
    "# feature matching\n",
    "bf = cv.BFMatcher()\n",
    "\n",
    "matches = bf.knnMatch(descriptors_gray, descriptors_edge, k=2)\n",
    "\n",
    "good_matches = []\n",
    "total_correct = 0\n",
    "for m, n in matches:\n",
    "    if m.distance < 0.9 * n.distance:\n",
    "        good_matches.append(m)\n",
    "        total_correct += 1\n",
    "\n",
    "img_matches = cv.drawMatches(gnd_trth_gray, keypoints_gray, img_mexican_hat, keypoints_edge, good_matches, None, flags=cv.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "\n",
    "ground_truth_labels = np.zeros(len(matches))\n",
    "predicted_labels = np.zeros(len(matches))\n",
    "for i, match in enumerate(matches):\n",
    "    if i in [m.queryIdx for m in good_matches]:  # check if the index is in good_matches\n",
    "        predicted_labels[i] = 1\n",
    "    if i < len(good_matches):\n",
    "        ground_truth_labels[i] = 1\n",
    "\n",
    "conf_matrix = confusion_matrix(ground_truth_labels, predicted_labels)\n",
    "\n",
    "print(f\"accuracy: {ground_truth_keypoints / predicted_keypoints :.2%}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"All Truth Keypoints\", len(keypoints_gray))\n",
    "print(\"All Estimated Keypoints\", len(keypoints_edge))\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.imshow(img_matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the matcher.match() method to find the matches between the descriptors of the two sets of keypoints. \n",
    "this method returns a list of matches where each match contains information about the corresponding keypoints in the two sets and the distance between their descriptors.\n",
    "\n",
    "Optionally, we can perform k-nearest neighbors (KNN) search instead of simple matching by using the matcher. so for each descriptor in the first set, the knnMatch() method finds the k nearest neighbors in the second set of descriptors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sourse_points = []\n",
    "distination_points = []\n",
    "\n",
    "for match in good_matches:\n",
    "    sourse_points.append(keypoints_gray[match.queryIdx].pt)\n",
    "    distination_points.append(keypoints_edge[match.trainIdx].pt)\n",
    "\n",
    "src_pts = np.float32(sourse_points).reshape(-1, 1, 2)\n",
    "dst_pts = np.float32(distination_points).reshape(-1, 1, 2)\n",
    "\n",
    "x_min = min([pt[0][0] for pt in dst_pts])\n",
    "x_max = max([pt[0][0] for pt in dst_pts])\n",
    "y_min = min([pt[0][1] for pt in dst_pts])\n",
    "y_max = max([pt[0][1] for pt in dst_pts])\n",
    "\n",
    "rectangle = Rectangle((x_min, y_min), (x_max - x_min), (y_max - y_min), linewidth=2, edgecolor='r', facecolor='none')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 5))\n",
    "ax.imshow(img_matches, cmap='gray')\n",
    "ax.add_patch(rectangle)\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(20, 5))\n",
    "# ax.imshow(img_matches, cmap='gray')\n",
    "\n",
    "# # Iterate over each point in dst_pts\n",
    "# for pt in dst_pts:\n",
    "#     x, y = pt[0]\n",
    "#     # Define the width and height of the rectangle (adjust as needed)\n",
    "#     rect_width = 10\n",
    "#     rect_height = 10\n",
    "#     # Calculate the coordinates of the top-left corner of the rectangle\n",
    "#     x_min = x - rect_width / 2\n",
    "#     y_min = y - rect_height / 2\n",
    "#     # Create and add the rectangle patch to the plot\n",
    "#     rectangle = Rectangle((x_min, y_min), rect_width, rect_height, linewidth=1, edgecolor='r', facecolor='none')\n",
    "#     ax.add_patch(rectangle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 5))\n",
    "ax.imshow(img_matches, cmap='gray')\n",
    "\n",
    "for pt in dst_pts:\n",
    "    x, y = pt[0]\n",
    "    \n",
    "    rect_width = 10\n",
    "    rect_height = 10\n",
    "    \n",
    "    x_min = x - rect_width / 2\n",
    "    y_min = y - rect_height / 2\n",
    "    \n",
    "    rectangle = Rectangle((x_min, y_min), rect_width, rect_height, linewidth=1, edgecolor='r', facecolor='none')\n",
    "    ax.add_patch(rectangle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "homography, _ = cv.findHomography(src_pts, dst_pts, cv.RANSAC)\n",
    "\n",
    "h, w = img_mexican_hat.shape[:2]\n",
    "pts = np.float32([[0, 0], [0, h - 1], [w - 1, h - 1], [w - 1, 0]]).reshape(-1, 1, 2)\n",
    "transformed_pts = cv.perspectiveTransform(pts, homography)\n",
    "min_x, min_y = np.int32(transformed_pts.min(axis=0).ravel())\n",
    "max_x, max_y = np.int32(transformed_pts.max(axis=0).ravel())\n",
    "\n",
    "result_image = gnd_trth_gray.copy()\n",
    "rectangle = cv.rectangle(result_image, (min_x, min_y), (max_x, max_y), (255, 255, 255), 1)\n",
    "\n",
    "plt.imshow(rectangle ,cmap='gray')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
