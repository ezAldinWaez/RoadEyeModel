{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background Subtraction Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from expt_utils import *\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_ground_truth = cv.imread(f'{IMG_DIR}/ground_truth/00025_8880.jpg')\n",
    "img_ground_truth = cv.cvtColor(img_ground_truth, cv.COLOR_BGR2GRAY)\n",
    "img_ground_truth= cv.resize(img_ground_truth, (int(img_ground_truth.shape[1] * 0.6), int(img_ground_truth.shape[0] * 0.6)))\n",
    "background_dir = f'{DS_DIR}/test/images/'\n",
    "\n",
    "imgs = []\n",
    "\n",
    "for filename in os.listdir(background_dir):\n",
    "    if filename.endswith('.jpg') and filename.split('_')[0] == '00025':\n",
    "        img_path = os.path.join(background_dir, filename)\n",
    "        img = cv.imread(img_path)\n",
    "        img = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "        imgs.append(img)\n",
    "\n",
    "frames_stack = np.stack(imgs, axis=-1)\n",
    "\n",
    "background_median = np.median(frames_stack, axis=-1).astype(np.uint8)\n",
    "background_median = cv.resize(background_median, (int(background_median.shape[1] * 0.6), int(background_median.shape[0] * 0.6)))\n",
    "\n",
    "plt.imshow(background_median, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foreground_images = []\n",
    "\n",
    "save_dir = 'out/accounts'\n",
    "\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "idx = 1\n",
    "for filename in os.listdir(background_dir):\n",
    "    if filename.endswith('.jpg')  and filename.split('_')[0] == '00025':\n",
    "        img_path = os.path.join(background_dir, filename)\n",
    "        frame = cv.imread(img_path)\n",
    "        frame = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "        frame = cv.resize(frame, (int(frame.shape[1] * 0.6), int(frame.shape[0] * 0.6)))\n",
    "        foreground = cv.absdiff(frame, background_median)\n",
    "        foreground_images.append(foreground)\n",
    "        filename = f'foreground_{idx}.jpg'\n",
    "        save_path = os.path.join(save_dir, filename)\n",
    "        cv.imwrite(save_path, foreground)\n",
    "        idx += 1\n",
    "\n",
    "for i, foreground in enumerate(foreground_images):\n",
    "    cv.imshow('Foreground Image {}'.format(i), foreground)\n",
    "    cv.waitKey(0)\n",
    "\n",
    "plt.imshow(foreground_images[11], cmap='gray')\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bf = cv.BFMatcher()\n",
    "# orb = cv.SIFT_create()\n",
    "# img = foreground_images[10]\n",
    "# dir = '../experiments/img/09'\n",
    "\n",
    "# img_ground_truths = []\n",
    "\n",
    "# for filename in os.listdir(dir):\n",
    "#     if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "#         img_path = os.path.join(dir, filename)\n",
    "#         img_ground_truth = cv.imread(img_path)\n",
    "#         img_ground_truth = cv.cvtColor(img_ground_truth, cv.COLOR_BGR2RGB)\n",
    "#         img_ground_truths.append(img_ground_truth)\n",
    "        \n",
    "\n",
    "# bf = cv.BFMatcher()\n",
    "# orb = cv.SIFT_create()\n",
    "\n",
    "# img = foreground_images[10]\n",
    "\n",
    "# all_bbox_lists = []\n",
    "# good_matches = []\n",
    "\n",
    "# for img_ground_truth in img_ground_truths:\n",
    "#     keypoints_frame, descriptors_frame = orb.detectAndCompute(img, None)\n",
    "#     keypoints_grd, descriptors_grd = orb.detectAndCompute(img_ground_truth, None)\n",
    "\n",
    "#     matches = bf.knnMatch(descriptors_grd, descriptors_frame, k=2)\n",
    "\n",
    "#     for m, n in matches:\n",
    "#         if m.distance < 1 * n.distance:\n",
    "#             good_matches.append(m)\n",
    "    \n",
    "#     bbox_list = []\n",
    "#     for match in good_matches:\n",
    "#         frame_idx = match.trainIdx\n",
    "#         frame_pt = keypoints_frame[frame_idx].pt\n",
    "#         bbox = ((int(frame_pt[0] - 0), int(frame_pt[1] - 0)),\n",
    "#                 (int(frame_pt[0] + 0), int(frame_pt[1] + 0))) \n",
    "#         bbox_list.append(bbox)\n",
    "    \n",
    "#     all_bbox_lists.append(bbox_list)\n",
    "\n",
    "# merged_bbox_list = []\n",
    "# for bbox_list in all_bbox_lists:\n",
    "#     merged_bbox_list.extend(bbox_list)\n",
    "\n",
    "# for bbox in merged_bbox_list:\n",
    "#     cv.rectangle(img, bbox[0], bbox[1], (0, 255, 0), 5)\n",
    "\n",
    "# plt.figure(figsize=(20, 5))\n",
    "# plt.imshow(img)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature detection on resized image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bf = cv.BFMatcher()\n",
    "orb = cv.ORB_create()\n",
    "img_subtracted = foreground_images[11]\n",
    "\n",
    "keypoints_img_ground_truth, descriptors_img_ground_truth = orb.detectAndCompute(img_ground_truth, None)\n",
    "keypoints_img_subtracted, descriptors_img_subtracted = orb.detectAndCompute(img_subtracted, None)\n",
    "\n",
    "matches = bf.knnMatch(descriptors_img_ground_truth, descriptors_img_subtracted, k=2)\n",
    "\n",
    "good_matches = []\n",
    "total_correct = 0\n",
    "for m, n in matches:\n",
    "    if m.distance < 0.9 * n.distance:\n",
    "        good_matches.append(m)\n",
    "        total_correct += 1\n",
    "\n",
    "img_matches = cv.drawMatches(img_ground_truth, keypoints_img_ground_truth, img_subtracted, keypoints_img_subtracted, good_matches, None, flags=cv.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "\n",
    "ground_truth_keypoints = total_correct\n",
    "predicted_keypoints = len(keypoints_img_subtracted)\n",
    "\n",
    "ground_truth_labels = np.zeros(len(matches))\n",
    "predicted_labels = np.zeros(len(matches))\n",
    "for i, match in enumerate(matches):\n",
    "    if i in [m.queryIdx for m in good_matches]:  # check if the index is in good_matches\n",
    "        predicted_labels[i] = 1\n",
    "    if i < len(good_matches):\n",
    "        ground_truth_labels[i] = 1\n",
    "\n",
    "conf_matrix = confusion_matrix(ground_truth_labels, predicted_labels)\n",
    "\n",
    "print(f\"accuracy: {ground_truth_keypoints / predicted_keypoints :.2%}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"All Truth Keypoints\", len(keypoints_img_ground_truth))\n",
    "print(\"All Estimated Keypoints\", len(keypoints_img_subtracted))\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.imshow(img_matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature detection on resized & shadow detection image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "def shadow_detection(image_gray):\n",
    "    image_rgb = cv.cvtColor(image_gray, cv.COLOR_GRAY2RGB)\n",
    "    lab_image = cv.cvtColor(image_rgb, cv.COLOR_RGB2LAB)\n",
    "\n",
    "    mean_l = np.mean(lab_image[:, :])\n",
    "    std_l = np.std(lab_image[:, :])\n",
    "\n",
    "    shadow_mask = lab_image[:, :] <= (mean_l - std_l/3)\n",
    "\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    cleaned_mask = cv.morphologyEx(shadow_mask.astype(np.uint8), cv.MORPH_OPEN, kernel)\n",
    "    shadow_mask_cleaned = cv.dilate(cleaned_mask, kernel, iterations=1)\n",
    "    shadow_mask_cleaned = cv.erode(shadow_mask_cleaned, kernel, iterations=1)\n",
    "\n",
    "    result_image = np.copy(image_gray)\n",
    "    result_image[shadow_mask_cleaned] = [0]\n",
    "\n",
    "    return result_image, shadow_mask_cleaned\n",
    "\n",
    "def shadow_remove(image_gray, shadow_mask):\n",
    "    image_float = image_gray.astype(np.float32)\n",
    "\n",
    "    shadow_pixels = np.where(shadow_mask)\n",
    "    avg_intensity_inside_shadow = np.mean(image_float[shadow_pixels[0], shadow_pixels[1]])\n",
    "    outside_shadow_mask = ~shadow_mask\n",
    "    outside_shadow_pixels = np.where(outside_shadow_mask)\n",
    "    avg_intensity_outside_shadow = np.mean(image_float[outside_shadow_pixels[0], outside_shadow_pixels[1]])\n",
    "\n",
    "    constants = avg_intensity_outside_shadow / avg_intensity_inside_shadow\n",
    "\n",
    "    image_float[shadow_pixels[0], shadow_pixels[1]] *= constants\n",
    "\n",
    "    result_image = np.clip(image_float, 0, 255).astype(np.uint8)\n",
    "\n",
    "    return result_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_subtracted = foreground_images[11]\n",
    "result_shadow_img, shadow_mask = shadow_detection(img_subtracted)\n",
    "img_subtracted_shadow_detected = shadow_remove(result_shadow_img,shadow_mask)\n",
    "\n",
    "plt.imshow(img_subtracted_shadow_detected, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature detection\n",
    "orb = cv.ORB_create()\n",
    "\n",
    "keypoints_img_ground_truth, descriptors_img_ground_truth = orb.detectAndCompute(img_ground_truth, None)\n",
    "keypoints_img_subtracted_shadow_detected, descriptors_img_subtracted_shadow_detected = orb.detectAndCompute(img_subtracted_shadow_detected, None)\n",
    "\n",
    "# object matching\n",
    "bf = cv.BFMatcher()\n",
    "\n",
    "matches = bf.knnMatch(descriptors_img_ground_truth, descriptors_img_subtracted_shadow_detected, k=2)\n",
    "\n",
    "good_matches = []\n",
    "total_correct = 0\n",
    "for m, n in matches:\n",
    "    if m.distance < 0.9 * n.distance:\n",
    "        good_matches.append(m)\n",
    "        total_correct += 1\n",
    "\n",
    "img_matches = cv.drawMatches(img_ground_truth, keypoints_img_ground_truth, img_subtracted_shadow_detected, keypoints_img_subtracted_shadow_detected, good_matches, None, flags=cv.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "\n",
    "ground_truth_keypoints = total_correct\n",
    "predicted_keypoints = len(keypoints_img_subtracted_shadow_detected)\n",
    "\n",
    "ground_truth_labels = np.zeros(len(matches))\n",
    "predicted_labels = np.zeros(len(matches))\n",
    "for i, match in enumerate(matches):\n",
    "    if i in [m.queryIdx for m in good_matches]:\n",
    "        predicted_labels[i] = 1\n",
    "    if i < len(good_matches):\n",
    "        ground_truth_labels[i] = 1\n",
    "\n",
    "conf_matrix = confusion_matrix(ground_truth_labels, predicted_labels)\n",
    "\n",
    "print(f\"accuracy: {ground_truth_keypoints / predicted_keypoints :.2%}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"All Truth Keypoints\", len(keypoints_img_ground_truth))\n",
    "print(\"All Estimated Keypoints\", len(keypoints_img_subtracted_shadow_detected))\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.imshow(img_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_descriptors_array = np.array(descriptors_img_ground_truth)\n",
    "\n",
    "num_objects = 4 \n",
    "kmeans = KMeans(n_clusters=num_objects)\n",
    "\n",
    "kmeans.fit(all_descriptors_array)\n",
    "\n",
    "cluster_labels = kmeans.labels_\n",
    "\n",
    "clusters = [[] for _ in range(num_objects)]\n",
    "for i, kp in enumerate(keypoints_img_ground_truth):\n",
    "    cluster_index = cluster_labels[i]\n",
    "    clusters[cluster_index].append(kp)\n",
    "\n",
    "for keypoints in clusters:\n",
    "    points = np.array([kp.pt for kp in keypoints], dtype=np.int32)\n",
    "    x, y, w, h = cv.boundingRect(points)\n",
    "    cv.rectangle(img_ground_truth, (x, y), (x + w, y + h), (255, 255, 255), 2)\n",
    "\n",
    "plt.imshow(img_ground_truth, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_img_features = []\n",
    "first_img_features.append(np.array([274, 211, 96, 57]))\n",
    "first_img_features.append(np.array([717, 84, 22, 18]))\n",
    "first_img_features.append(np.array([669, 81, 24, 21]))\n",
    "first_img_features.append(np.array([627, 125, 34, 25]))\n",
    "first_img_features.append(np.array([713, 67, 19, 15]))\n",
    "first_img_features.append(np.array([730, 60, 16, 16]))\n",
    "first_img_features.append(np.array([759, 68, 17, 13]))\n",
    "\n",
    "second_img_features = []\n",
    "second_img_features.append(np.array([514, 135, 49, 32]))\n",
    "second_img_features.append(np.array([681, 100, 26, 21]))\n",
    "second_img_features.append(np.array([710, 69, 19, 15]))\n",
    "second_img_features.append(np.array([743, 71, 19, 17]))\n",
    "second_img_features.append(np.array([739, 59, 15, 14]))\n",
    "\n",
    "first = foreground_images[0]\n",
    "second = foreground_images[1]\n",
    "\n",
    "orb = cv.ORB_create()\n",
    "\n",
    "keypoints_img_first, descriptors_img_first = orb.detectAndCompute(first, None)\n",
    "keypoints_img_second, descriptors_img_second = orb.detectAndCompute(second, None)\n",
    "\n",
    "# object matching\n",
    "bf = cv.BFMatcher()\n",
    "\n",
    "matches = bf.knnMatch(descriptors_img_first, descriptors_img_second, k=2)\n",
    "\n",
    "good_matches = []\n",
    "total_correct = 0\n",
    "first_object_id = []\n",
    "second_object_id = []\n",
    "\n",
    "for m, n in matches:\n",
    "    if m.distance < 1 * n.distance:\n",
    "        good_matches.append(m)\n",
    "        total_correct += 1\n",
    "        \n",
    "        kp_first_location = keypoints_img_first[m.queryIdx].pt\n",
    "        kp_second_location = keypoints_img_second[m.trainIdx].pt\n",
    "        cu_first_id = 0\n",
    "        cu_second_id = 0\n",
    "        for i, first_feature in enumerate(first_img_features):\n",
    "            x = int(first_feature[0] * .6)\n",
    "            y = int(first_feature[1] * .6)\n",
    "            w = int(first_feature[2] * .6)\n",
    "            h = int(first_feature[3] * .6)\n",
    "            if (x <= kp_first_location[0]) & (x+w >= kp_first_location[0]) & (y <= kp_first_location[1]) & (y+h >= kp_first_location[1]):\n",
    "                cu_first_id = i+1\n",
    "                break\n",
    "        for i, second_feature in enumerate(second_img_features):\n",
    "            x = int(second_feature[0] * .6)\n",
    "            y = int(second_feature[1] * .6)\n",
    "            w = int(second_feature[2] * .6)\n",
    "            h = int(second_feature[3] * .6)\n",
    "            if (x <= kp_second_location[0]) & (x+w >= kp_second_location[0]) & (y <= kp_second_location[1]) & (y+h >= kp_second_location[1]):\n",
    "                cu_second_id = i+1\n",
    "                break\n",
    "        if cu_first_id & cu_second_id: # to check that i get only features belong to objects that dataset has been annotated\n",
    "            first_object_id.append(cu_first_id)\n",
    "            second_object_id.append(cu_second_id)\n",
    "        # we will get object Id's less than total correct features that happen because there are some feature detected dataset didn't annotate their object\n",
    "        # total correct 146 and first,second object id 111\n",
    "\n",
    "df_objects_ids = pd.DataFrame({'first_objects':first_object_id, 'second_objects':second_object_id})\n",
    "df_objects_ids = df_objects_ids.groupby('second_objects')['first_objects'].apply(list).reset_index()\n",
    "\n",
    "print(df_objects_ids)\n",
    "\n",
    "for index, row in df_objects_ids.iterrows():\n",
    "    print(\"Object:\", row['second_objects'])\n",
    "    counts = pd.Series(row['first_objects']).value_counts()\n",
    "    total_count = len(row['first_objects'])\n",
    "    percentages = (counts / total_count) * 100\n",
    "    \n",
    "    for value, percentage in zip(counts.index, percentages):\n",
    "        print(\"Object:\", value, \"- Percentage:\", percentage)\n",
    "\n",
    "img_matches = cv.drawMatches(first, keypoints_img_first, second, keypoints_img_second, good_matches, None, flags=cv.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.imshow(img_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_objects_ids"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
