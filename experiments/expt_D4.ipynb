{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background Subtraction Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2 as cv\n",
    "import seaborn as sns\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_ground_truth = cv.imread('../experiments/img/09/00025_8880-5.jpg')\n",
    "img_ground_truth = cv.cvtColor(img_ground_truth, cv.COLOR_BGR2GRAY)\n",
    "img_ground_truth= cv.resize(img_ground_truth, (int(img_ground_truth.shape[1] * 0.4), int(img_ground_truth.shape[0] * 0.4)))\n",
    "background_dir = '../dataset/frames/test/video25'\n",
    "\n",
    "imgs = []\n",
    "\n",
    "for filename in os.listdir(background_dir):\n",
    "    if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "        img_path = os.path.join(background_dir, filename)\n",
    "        img = cv.imread(img_path)\n",
    "        img = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "        imgs.append(img)\n",
    "\n",
    "frames_stack = np.stack(imgs, axis=-1)\n",
    "\n",
    "background_median = np.median(frames_stack, axis=-1).astype(np.uint8)\n",
    "background_median = cv.resize(background_median, (int(background_median.shape[1] * 0.4), int(background_median.shape[0] * 0.4)))\n",
    "\n",
    "plt.imshow(img_ground_truth, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foreground_images = []\n",
    "\n",
    "for filename in os.listdir(background_dir):\n",
    "    if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "        img_path = os.path.join(background_dir, filename)\n",
    "        frame = cv.imread(img_path)\n",
    "        frame = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "        frame = cv.resize(frame, (int(frame.shape[1] * 0.4), int(frame.shape[0] * 0.4)))\n",
    "        foreground = cv.absdiff(frame, background_median)\n",
    "        foreground_images.append(foreground)\n",
    "\n",
    "for i, foreground in enumerate(foreground_images):\n",
    "    cv.imshow('Foreground Image {}'.format(i), foreground)\n",
    "    cv.waitKey(0)\n",
    "\n",
    "plt.imshow(foreground_images[11], cmap='gray')\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bf = cv.BFMatcher()\n",
    "# orb = cv.SIFT_create()\n",
    "# img = foreground_images[10]\n",
    "# dir = '../experiments/img/09'\n",
    "\n",
    "# img_ground_truths = []\n",
    "\n",
    "# for filename in os.listdir(dir):\n",
    "#     if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "#         img_path = os.path.join(dir, filename)\n",
    "#         img_ground_truth = cv.imread(img_path)\n",
    "#         img_ground_truth = cv.cvtColor(img_ground_truth, cv.COLOR_BGR2RGB)\n",
    "#         img_ground_truths.append(img_ground_truth)\n",
    "        \n",
    "\n",
    "# bf = cv.BFMatcher()\n",
    "# orb = cv.SIFT_create()\n",
    "\n",
    "# img = foreground_images[10]\n",
    "\n",
    "# all_bbox_lists = []\n",
    "# good_matches = []\n",
    "\n",
    "# for img_ground_truth in img_ground_truths:\n",
    "#     keypoints_frame, descriptors_frame = orb.detectAndCompute(img, None)\n",
    "#     keypoints_grd, descriptors_grd = orb.detectAndCompute(img_ground_truth, None)\n",
    "\n",
    "#     matches = bf.knnMatch(descriptors_grd, descriptors_frame, k=2)\n",
    "\n",
    "#     for m, n in matches:\n",
    "#         if m.distance < 1 * n.distance:\n",
    "#             good_matches.append(m)\n",
    "    \n",
    "#     bbox_list = []\n",
    "#     for match in good_matches:\n",
    "#         frame_idx = match.trainIdx\n",
    "#         frame_pt = keypoints_frame[frame_idx].pt\n",
    "#         bbox = ((int(frame_pt[0] - 0), int(frame_pt[1] - 0)),\n",
    "#                 (int(frame_pt[0] + 0), int(frame_pt[1] + 0))) \n",
    "#         bbox_list.append(bbox)\n",
    "    \n",
    "#     all_bbox_lists.append(bbox_list)\n",
    "\n",
    "# merged_bbox_list = []\n",
    "# for bbox_list in all_bbox_lists:\n",
    "#     merged_bbox_list.extend(bbox_list)\n",
    "\n",
    "# for bbox in merged_bbox_list:\n",
    "#     cv.rectangle(img, bbox[0], bbox[1], (0, 255, 0), 5)\n",
    "\n",
    "# plt.figure(figsize=(20, 5))\n",
    "# plt.imshow(img)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature detection on resized image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bf = cv.BFMatcher()\n",
    "orb = cv.ORB_create()\n",
    "img_subtracted = foreground_images[11]\n",
    "\n",
    "keypoints_img_ground_truth, descriptors_img_ground_truth = orb.detectAndCompute(img_ground_truth, None)\n",
    "keypoints_img_subtracted, descriptors_img_subtracted = orb.detectAndCompute(img_subtracted, None)\n",
    "\n",
    "matches = bf.knnMatch(descriptors_img_ground_truth, descriptors_img_subtracted, k=2)\n",
    "\n",
    "good_matches = []\n",
    "total_correct = 0\n",
    "TP = FP = TN = FN = 0\n",
    "for m, n in matches:\n",
    "    if m.distance < 1 * n.distance:\n",
    "        good_matches.append(m)\n",
    "        total_correct += 1\n",
    "        TP += 1 \n",
    "    else:\n",
    "        FP += 1\n",
    "\n",
    "img_matches = cv.drawMatches(img_ground_truth, keypoints_img_ground_truth, img_subtracted, keypoints_img_subtracted, good_matches, None, flags=cv.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "\n",
    "ground_truth_keypoints = total_correct\n",
    "predicted_keypoints = len(keypoints_img_subtracted)\n",
    "\n",
    "FN = len(keypoints_img_ground_truth) - TP\n",
    "TN = len(keypoints_img_subtracted) - TP - FP - FN\n",
    "\n",
    "print(f\"accuracy: {ground_truth_keypoints / predicted_keypoints :.2%}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(\"True Positives (TP):\", TP)\n",
    "print(\"False Positives (FP):\", FP)\n",
    "print(\"True Negatives (TN):\", TN)\n",
    "print(\"False Negatives (FN):\", FN)\n",
    "print(\"All Truth Keypoints\", len(keypoints_img_ground_truth))\n",
    "print(\"All Estimated Keypoints\", len(keypoints_img_subtracted))\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.imshow(img_matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature detection on resized & shadow detection image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "def shadow_detection(image_gray):\n",
    "    image_rgb = cv.cvtColor(image_gray, cv.COLOR_GRAY2RGB)\n",
    "    lab_image = cv.cvtColor(image_rgb, cv.COLOR_RGB2LAB)\n",
    "\n",
    "    mean_l = np.mean(lab_image[:, :])\n",
    "    std_l = np.std(lab_image[:, :])\n",
    "\n",
    "    shadow_mask = lab_image[:, :] <= (mean_l - std_l/3)\n",
    "\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    cleaned_mask = cv.morphologyEx(shadow_mask.astype(np.uint8), cv.MORPH_OPEN, kernel)\n",
    "    shadow_mask_cleaned = cv.dilate(cleaned_mask, kernel, iterations=1)\n",
    "    shadow_mask_cleaned = cv.erode(shadow_mask_cleaned, kernel, iterations=1)\n",
    "\n",
    "    result_image = np.copy(image_gray)\n",
    "    result_image[shadow_mask_cleaned] = [0]\n",
    "\n",
    "    return result_image, shadow_mask_cleaned\n",
    "\n",
    "def shadow_remove(image_gray, shadow_mask):\n",
    "    image_float = image_gray.astype(np.float32)\n",
    "\n",
    "    shadow_pixels = np.where(shadow_mask)\n",
    "    avg_intensity_inside_shadow = np.mean(image_float[shadow_pixels[0], shadow_pixels[1]])\n",
    "    outside_shadow_mask = ~shadow_mask\n",
    "    outside_shadow_pixels = np.where(outside_shadow_mask)\n",
    "    avg_intensity_outside_shadow = np.mean(image_float[outside_shadow_pixels[0], outside_shadow_pixels[1]])\n",
    "\n",
    "    constants = avg_intensity_outside_shadow / avg_intensity_inside_shadow\n",
    "\n",
    "    image_float[shadow_pixels[0], shadow_pixels[1]] *= constants\n",
    "\n",
    "    result_image = np.clip(image_float, 0, 255).astype(np.uint8)\n",
    "\n",
    "    return result_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_subtracted = foreground_images[11]\n",
    "result_shadow_img, shadow_mask = shadow_detection(img_subtracted)\n",
    "img_subtracted_shadow_detected = shadow_remove(result_shadow_img,shadow_mask)\n",
    "\n",
    "plt.imshow(img_subtracted_shadow_detected, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature detection\n",
    "orb = cv.ORB_create()\n",
    "\n",
    "keypoints_img_ground_truth, descriptors_img_ground_truth = orb.detectAndCompute(img_ground_truth, None)\n",
    "keypoints_img_subtracted_shadow_detected, descriptors_img_subtracted_shadow_detected = orb.detectAndCompute(img_subtracted_shadow_detected, None)\n",
    "\n",
    "# object matching\n",
    "bf = cv.BFMatcher()\n",
    "\n",
    "matches = bf.knnMatch(descriptors_img_ground_truth, descriptors_img_subtracted_shadow_detected, k=2)\n",
    "\n",
    "good_matches = []\n",
    "total_correct = 0\n",
    "TP = FP = TN = FN = 0\n",
    "for m, n in matches:\n",
    "    if m.distance < 1 * n.distance:\n",
    "        good_matches.append(m)\n",
    "        total_correct += 1\n",
    "        TP += 1 \n",
    "    else:\n",
    "        FP += 1\n",
    "\n",
    "img_matches = cv.drawMatches(img_ground_truth, keypoints_img_ground_truth, img_subtracted_shadow_detected, keypoints_img_subtracted_shadow_detected, good_matches, None, flags=cv.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "\n",
    "ground_truth_keypoints = total_correct\n",
    "predicted_keypoints = len(keypoints_img_subtracted_shadow_detected)\n",
    "\n",
    "TN = len(keypoints_img_subtracted_shadow_detected) - (TP + FP)\n",
    "FN = len(keypoints_img_subtracted_shadow_detected) - TP - FP - TN\n",
    "\n",
    "print(f\"accuracy: {ground_truth_keypoints / predicted_keypoints :.2%}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(\"True Positives (TP):\", TP)\n",
    "print(\"False Positives (FP):\", FP)\n",
    "print(\"True Negatives (TN):\", TN)\n",
    "print(\"False Negatives (FN):\", FN)\n",
    "print(\"All Truth Keypoints\", len(keypoints_img_ground_truth))\n",
    "print(\"All Estimated Keypoints\", len(keypoints_img_subtracted_shadow_detected))\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.imshow(img_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
