{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shadow Detection and Removal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A shadow appears on an area when the light from a source cannot reach the area due to obstruction by an object. \n",
    "\n",
    "Shadow in general are of two types (by looking to the videos frames we find that during our project we will meet both of them): hard and soft shadows. The soft shadows retain the texture of the background surface, whereas the hard shadows are too dark and have little texture.\n",
    "\n",
    "Most of the shadow detection methods need multiple images for camera calibration, But the best technique must be able to extract shadows from a single image where we will consider this technique for our project. \n",
    "\n",
    "A shadow detection method is selected based on the mean value of RGB image in A and B planes of LAB equivalent of the image.\n",
    "\n",
    "<img align=\"left\" src=\"img/lab_color_space.jpg\" style=\" width:300px; padding-right: 30px;  \" /> \n",
    "\n",
    "<u>**The LAB colour space:**</u> The LAB colour space has three channels − L is the Lightness channel, A and B are the two colour channels.\n",
    "\n",
    "The L channel has values ranging from 0 up to 100, which correspond to different shades from black to white. The A channel has values ranging from −128 up to +127 and gives the red to green ratio. The B channel also has values ranging from −128 up to +127 and gives the yellow to blue ratio. \n",
    "\n",
    "Thus, a high value in A or B channel represents a colour having more red or yellow and a low value represents a colour having more green or blue.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...\n",
    "\n",
    "...\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will apply this task by Detecting the shadows of objects first, then try to remove these shadows.\n",
    "\n",
    "<u>**1.Shadow Detection:**</u> \n",
    "\n",
    "An approach to detect the shadows areas in a single RGB image is convert from RGB to LAB color space. Since the shadow regions are darker and less illuminated than the surroundings, it is easy to locate them in the L channel since the L channel gives lightness information. The B channel values are also lesser in the shadow areas in most of the outdoor images. \n",
    "\n",
    "Thus combining the values from L and B channels, the pixels with values less than a threshold are identified as shadow pixels, and others as non-shadow pixels. The method works well only for images whose yellow to blue ratio is maintained within a range.\n",
    "\n",
    "The mean value of the image in A and B channels are calculated.\n",
    "\n",
    "The major steps involved in the shadow detection phase are:  \n",
    "1. Convert the RGB image to a LAB image. \n",
    "2. Compute the mean values of the pixels in L, A and B planes of the image separately. \n",
    "3. If mean (A) + mean (B) ≤ 256 then Classify the pixels with a value in L ≤(mean(L) – standard deviation (L)/3) as shadow pixels and others as non-shadow pixels. \n",
    "4. Else classify the pixels with lower values in both L and B planes as shadow pixels and others as non-shadow pixels.\n",
    "\n",
    "The shadow detection using this pixel-based method may classify some non shadow pixels as shadow pixels. Isolated pixels are removed using morphological \n",
    "operation called cleaning. \n",
    "\n",
    "The misclassified pixels are removed using dilation followed by erosion. Also area-based thresholding is done, so that only regions with a number of pixels greater than a threshold can be considered as shadow regions. All these morphological operations will help to eliminate misclassification of pixels.\n",
    "\n",
    "<u>**2.Shadow Removal and Edge Correction:**</u> \n",
    "\n",
    "Shadow removal is done by multiplying R, G and B channels of the shadow pixels using appropriate constants. Each shadow region is considered separately. The ratio of the average of each channel in the near non-shadow region to that in the shadow region is taken as a constant for each channel. The shadow regions achieve almost the same illumination as the non-shadow regions. But over-illumination may occur towards the edges of shadow. \n",
    "\n",
    "Since shadow regions are not uniformly illuminated, the same constant for the entire shadow region will create over-illuminated areas near the shadow edges. This is overcome by applying a median filter on the over-illuminated areas. Thus a shadow-free image without over-illuminated edges is obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "\n",
    "from expt_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread(f'{IMG_DIR}/simple_object_2.jpg')\n",
    "img_gray = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "\n",
    "cv.imshow('Image', img)\n",
    "cv.imshow('Image Gray', img_gray)\n",
    "\n",
    "destroy_when_esc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shadow_detection(image):\n",
    "\n",
    "    lab_image = cv.cvtColor(image, cv.COLOR_RGB2LAB)\n",
    "\n",
    "    mean_l = np.mean(lab_image[:, :, 0])\n",
    "    mean_a = np.mean(lab_image[:, :, 1])\n",
    "    mean_b = np.mean(lab_image[:, :, 2])\n",
    "    std_l = np.std(lab_image[:, :, 0])\n",
    "\n",
    "    if mean_a + mean_b <= 256:\n",
    "        shadow_mask = lab_image[:, :, 0] <= (mean_l - std_l/3)\n",
    "    else:\n",
    "        shadow_mask = (lab_image[:, :, 0] < mean_l) & (lab_image[:, :, 2] < mean_b)\n",
    "\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    cleaned_mask = cv.morphologyEx(shadow_mask.astype(np.uint8), cv.MORPH_OPEN, kernel)\n",
    "\n",
    "    shadow_mask_cleaned = cv.dilate(cleaned_mask, kernel, iterations=1)\n",
    "    shadow_mask_cleaned = cv.erode(shadow_mask_cleaned, kernel, iterations=1)\n",
    "    \n",
    "    # non_shadow_mask_cleaned = ~shadow_mask_cleaned\n",
    "\n",
    "    result_image = np.copy(image)\n",
    "    result_image[shadow_mask_cleaned] = [0,0,0]  \n",
    "\n",
    "    return result_image, shadow_mask_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shadow_remove(image, shadow_mask):\n",
    "    image_float = image.astype(np.float32)\n",
    "\n",
    "    shadow_pixels = np.where(shadow_mask)\n",
    "\n",
    "    avg_rgb_inside_shadow = np.zeros((3,))\n",
    "    avg_rgb_outside_shadow = np.zeros((3,))\n",
    "\n",
    "    for channel in range(3):\n",
    "        avg_rgb_inside_shadow[channel] = np.mean(image_float[shadow_pixels[0], shadow_pixels[1], channel])\n",
    "\n",
    "    outside_shadow_mask = ~shadow_mask\n",
    "    outside_shadow_pixels = np.where(outside_shadow_mask)\n",
    "    \n",
    "    for channel in range(3):\n",
    "        avg_rgb_outside_shadow[channel] = np.mean(image_float[outside_shadow_pixels[0], outside_shadow_pixels[1], channel])\n",
    "\n",
    "    constants = avg_rgb_outside_shadow / avg_rgb_inside_shadow\n",
    "\n",
    "    for channel in range(3):\n",
    "        image_float[shadow_pixels[0], shadow_pixels[1], channel] *= constants[channel]\n",
    "\n",
    "    result_image = np.clip(image_float, 0, 255).astype(np.uint8)\n",
    "\n",
    "    return result_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_shadow_img, shadow_mask = shadow_detection(img)\n",
    "final_result_img = shadow_remove(result_shadow_img, shadow_mask)\n",
    "\n",
    "cv.imshow('Image', img)\n",
    "cv.imshow('Result Shadow Img', result_shadow_img)\n",
    "cv.imshow('Shadow Mask', shadow_mask)\n",
    "cv.imshow('Final Result Img', final_result_img)\n",
    "\n",
    "destroy_when_esc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found that shadow edge correction is done to reduce the errors in the shadow boundary very well.\n",
    "\n",
    "We only could reduce the errors in the shadow and not to remove it at all because several factors, for examples:\n",
    "- Extract shadows only from a single image: this lead the algorithm to Limited Perspective, Ambiguity in Shadow Detection and Loss of Depth Information.\n",
    "- Non-uniform illumination: The illumination is not uniform in the shadow region. Towards the shadow boundary, diffusion takes place."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
