{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Detection Manually Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall our first step at Object Detection will be with manual methods, this will offer a valuable learning experience, enabling us to develop fundamental skills and gain practical insights for further exploration and advancement in the field of image processing in context of Object Detection.\n",
    "\n",
    "These manual ways will include Background Model Initialization and Adaptive Background Subtraction with Gaussian Mixture Models (GMM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...\n",
    "\n",
    "...\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two ways depend on subtracting each frame from the first frame, this will lead to separate foreground objects from the background in image sequences,\n",
    "the foreground objects include the objects that have moved frame by frame.\n",
    "\n",
    "But there is a significant difference in  how the background model is initialized and updated between these approaches:\n",
    "\n",
    "<u>**1.Background Model Initialization:**</u> initializes the background model using the first frame and calculates the foreground mask based on pixel-wise differences.\n",
    "\n",
    "<u>**2.Adaptive Background Subtraction with Gaussian Mixture Models (GMM):**</u> uses an adaptive background subtraction algorithm based on Gaussian mixture model, which automatically updates the background model internally without explicit initialization and manual thresholding.\n",
    "\n",
    "after that we apply a threshold to prepare the result image for object detection process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "from expt_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_DIR = make_out_dir('06')\n",
    "\n",
    "FRAMES_DIR = '../dataset/frames/test/00062'\n",
    "\n",
    "frame_files = sorted([os.path.join(FRAMES_DIR, f) for f in os.listdir(FRAMES_DIR) if f.endswith(('.jpg', '.png'))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background Model Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg_frame = cv2.imread(frame_files[0])\n",
    "\n",
    "bg_frame_gray = cv2.cvtColor(bg_frame, cv2.COLOR_BGR2GRAY).astype(np.float32)\n",
    "\n",
    "for frame_file in frame_files[1:]:\n",
    "\n",
    "    frame = cv2.imread(frame_file)\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY).astype(np.float32)\n",
    "    \n",
    "    diff = cv2.absdiff(gray_frame, bg_frame_gray).astype(np.uint8)\n",
    "    \n",
    "    _, fg_mask = cv2.threshold(diff, 30, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    _, axes = plt.subplots(1, 3, figsize=(20, 8))\n",
    "    axes[0].imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "    axes[0].set_title('Original Frame')\n",
    "\n",
    "    axes[1].imshow(diff, cmap='gray')\n",
    "    axes[1].set_title('Differential Frame')\n",
    "\n",
    "    axes[2].imshow(fg_mask, cmap='gray')\n",
    "    axes[2].set_title('Foreground Mask')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaptive Background Subtraction with Gaussian Mixture Models (GMM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg_subtractor = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "first_frame = cv2.imread(frame_files[0])\n",
    "bg_subtractor.apply(first_frame)\n",
    "\n",
    "for frame_file in frame_files:\n",
    "    frame = cv2.imread(frame_file)\n",
    "    \n",
    "    fg_mask = bg_subtractor.apply(frame)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    axes[0].imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "    axes[0].set_title('Original Frame')\n",
    "\n",
    "    axes[1].imshow(fg_mask, cmap='gray')\n",
    "    axes[1].set_title('Foreground Mask')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contour Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_area_threshold = 200\n",
    "max_area_threshold = 1000  \n",
    "for frame_file in frame_files:\n",
    "\n",
    "    frame = cv2.imread(frame_file)\n",
    "    \n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    blurred_frame = cv2.GaussianBlur(gray_frame, (5, 5), 0)\n",
    "    \n",
    "    edges = cv2.Canny(blurred_frame, 50, 150)\n",
    "    \n",
    "    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    vehicles = []\n",
    "    for contour in contours:\n",
    "        area = cv2.contourArea(contour)\n",
    "        if min_area_threshold < area < max_area_threshold:\n",
    "            vehicles.append(contour)\n",
    "    \n",
    "    frame_with_vehicles = frame.copy()\n",
    "    cv2.drawContours(frame_with_vehicles, vehicles, -1, (0, 255, 0), 2)\n",
    "    \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(cv2.cvtColor(frame_with_vehicles, cv2.COLOR_BGR2RGB))\n",
    "    plt.title('Frame with Vehicles')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...\n",
    "\n",
    "...\n",
    "\n",
    "..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
